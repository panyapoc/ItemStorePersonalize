{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Our First Recommendation Campaign\n",
    "\n",
    "CloudFormation has created the infrastructure of our website for us (see the URL in the CloudFormation 'stack outputs' to visit it in your browser), but now it's up to us to enrich it with personalized recommendations!\n",
    "\n",
    "This notebook will walk you through the steps to build an initial recommendation model to rank the products on the homepage, so it's more relevant to logged-in users.\n",
    "\n",
    "In further notebooks, we'll add other kinds of recommendation models to the website and enrich our base models with metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Python notebooks (if you're new to them)\n",
    "\n",
    "\"Notebooks\" like this break code up into **cells**, alongside formatted comment cells like this one.\n",
    "\n",
    "You don't *have* to use Amazon Personalize via notebooks or via Python - we're just using it as a way to interactively show the steps.\n",
    "\n",
    "To run a cell you can press the triangular `Run` button at the top of the page - or press `Shift+Enter` while you have the cell selected.\n",
    "\n",
    "The order in which cells ran is shown in square brackets next to the cell. `[ ]:` means the cell hasn't been run yet, and `[*]:` means it's currently running. `[1]:` means it ran first, and so on. Only one cell executes at a time, so if you start multiple they'll queue up and run in requested order.\n",
    "\n",
    "Simply follow the instructions below and execute the code cells to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the stack\n",
    "\n",
    "Let's review what's already been done for us, and what we'll need to do to get recommendations live:\n",
    "\n",
    "- A **staging bucket** has been created in S3 for us to use for data preparation\n",
    "- The **input files** provided during stack creation (`ProductSource`, `UserSource`, `InteractionSource`) have been copied to the bucket (in the `/raw` folder prefix)\n",
    "- The **products** have been loaded into the **products table** of DynamoDB (and from there automatically synced to the site's Elasticsearch cluster)\n",
    "    - ...So products are viewable and searchable in the website.\n",
    "- The **users** have been loaded into the **users table** of DynamoDB\n",
    "    - ...Populating the 'log in as' dropdown menu\n",
    "- Three **Lambda functions** (plus several others) have been published as API endpoints to connect recommendations to the app:\n",
    "    - `GetRecommendations`, for core/homepage recommendations by user\n",
    "    - `GetRecommendationsByItem`, for personalized recommendations per user in the context of an item\n",
    "    - `Rerank`, to re-rank the relevance of a set of candidate items to suggest to a user\n",
    "- Another **Lambda function** has been published to *push live click-stream data back in* to Personalize recommendation campaigns.\n",
    "\n",
    "We've already populated some helpful environment variables to navigate the stack, via this notebook's [lifecycle configuration script](https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "for envvar in [\n",
    "    \"CF_STACK_NAME\",\n",
    "    \"LAMBDA_GETITEMRECS_ARN\",\n",
    "    \"LAMBDA_GETRECS_ARN\",\n",
    "    \"LAMBDA_RERANK_ARN\",\n",
    "    \"LAMBDA_POSTCLICK_ARN\",\n",
    "    \"STAGING_BUCKET\"\n",
    "]:\n",
    "    print(f\"{envvar} = {os.environ[envvar]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add recommendations to the website**, what we need to do is:\n",
    "\n",
    "1. **Prepare** the data in the correct format in S3\n",
    "2. **Train** models and **deploy** them to \"campaigns\" in Amazon Personalize\n",
    "3. **Update** the environment variable configurations of these Lambda functions, to point them at Personalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to AWS and managing access\n",
    "\n",
    "Since this notebook is running in an Amazon SageMaker notebook instance created by the CloudFormation stack, we've already been set up with the access we need to call relevant AWS services - with no need to provide credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3  # (The AWS SDK for Python)\n",
    "\n",
    "personalize = boto3.client(\"personalize\")  # The administrative API e.g. *training* models\n",
    "personalize_runtime = boto3.client(\"personalize-runtime\")  # The runtime API e.g. *using* models\n",
    "s3 = boto3.resource(\"s3\")  # Cloud object storage (for our data!)\n",
    "\n",
    "# We'll quickly grab our AWS Account ID while we're here, which might be needed later:\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...However (since CloudFormation doesn't set up any Personalize stuff for us), we'll still need to **grant the Personalize service access to our staging bucket**.\n",
    "\n",
    "We do this in two steps;\n",
    "\n",
    "1. Creating a **Role** in the Identity & Access Management (IAM) service which has the required permissions and which we allow Amazon Personalize to *assume* when running jobs:\n",
    "2. Applying a **Bucket Policy** in Amazon S3 to grant the access from the S3 side.\n",
    "\n",
    "### Creating the role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "from botocore import exceptions as botoexceptions\n",
    "\n",
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = f\"{os.environ['CF_STACK_NAME']}-PersonalizeRole\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\n",
    "        # Only Amazon Personalize service may assume this role:\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Principal\": { \"Service\": \"personalize.amazonaws.com\" },\n",
    "        \"Action\": \"sts:AssumeRole\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "try:\n",
    "    create_role_response = iam.create_role(\n",
    "        RoleName=role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(assume_role_policy_document)\n",
    "    )\n",
    "    \n",
    "    # We'll use a custom, inline policy tweaking the AWS-managed \"AmazonPersonalizeFullAccess\" policy to\n",
    "    # be more specific about which S3 bucket can be accessed (only our staging bucket).\n",
    "    iam.put_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyName=\"InlinePolicy\",\n",
    "        PolicyDocument=json.dumps({\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "                {\n",
    "                    # Any action on any Personalize resources is permitted (quite loose!):\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": [\"personalize:*\"],\n",
    "                    \"Resource\": \"*\",\n",
    "                },\n",
    "                {\n",
    "                    # Allow Personalize jobs/etc to log metrics in CloudWatch:\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": [\n",
    "                        \"cloudwatch:PutMetricData\",\n",
    "                        \"cloudwatch:ListMetrics\",\n",
    "                    ],\n",
    "                    \"Resource\": \"*\",\n",
    "                },\n",
    "                {\n",
    "                    # Grant access specifically to our S3 Staging bucket\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": [\n",
    "                        \"s3:GetObject\",\n",
    "                        \"s3:PutObject\",\n",
    "                        \"s3:DeleteObject\",\n",
    "                        \"s3:ListBucket\",\n",
    "                    ],\n",
    "                    \"Resource\": [\n",
    "                        f\"arn:aws:s3:::{os.environ['STAGING_BUCKET']}\",\n",
    "                        f\"arn:aws:s3:::{os.environ['STAGING_BUCKET']}/*\",\n",
    "                    ],\n",
    "                },\n",
    "                {\n",
    "                    # Allow passing roles to Personalize service:\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": [\"iam:PassRole\"],\n",
    "                    \"Resource\": \"*\",\n",
    "                    \"Condition\": {\n",
    "                        \"StringEquals\": {\n",
    "                            \"iam:PassedToService\": \"personalize.amazonaws.com\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "    )\n",
    "\n",
    "    print(\"Waiting to allow new IAM role policy to propagate...\")\n",
    "    time.sleep(20)\n",
    "    role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "except botoexceptions.ClientError as err:\n",
    "    if err.response[\"Error\"][\"Code\"] == \"EntityAlreadyExists\":\n",
    "        print(\"Using pre-existing role\")\n",
    "        role_arn = f\"arn:aws:iam::{account_id}:role/{role_name}\"\n",
    "    else:  # Some other problem\n",
    "        raise err\n",
    "\n",
    "print(role_arn)\n",
    "%store role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Bucket Policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": { \"Service\": \"personalize.amazonaws.com\" },\n",
    "            \"Action\": [ \"s3:GetObject\", \"s3:ListBucket\" ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{os.environ['STAGING_BUCKET']}\",\n",
    "                f\"arn:aws:s3:::{os.environ['STAGING_BUCKET']}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.BucketPolicy(os.environ[\"STAGING_BUCKET\"]).put(Policy=json.dumps(bucket_policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the project: Create a Dataset Group\n",
    "\n",
    "The highest level construct in Amazon Personalize is the **dataset group**. You can think of it like a project: a container into which we'll put *up to 1 of each type of dataset* supported by the service, which we can then use to train some models and deploy some campaigns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_dataset_group_response = personalize.create_dataset_group(\n",
    "        name=f\"{os.environ['CF_STACK_NAME']}-dataset-group\"\n",
    "    )\n",
    "\n",
    "    dataset_group_arn = create_dataset_group_response[\"datasetGroupArn\"]\n",
    "    print(json.dumps(create_dataset_group_response, indent=2))\n",
    "\n",
    "except botoexceptions.ClientError as err:\n",
    "    # If the dataset group already exists, we'll just use the existing:\n",
    "    if err.response[\"Error\"][\"Code\"] == \"ResourceAlreadyExistsException\":\n",
    "        print(\"Dataset Group already exists - scraping ARN from error message\")\n",
    "        msg = err.response[\"Error\"][\"Message\"]\n",
    "        dataset_group_arn = msg[msg.index(\"arn:aws:personalize\"):].partition(\" \")[0]\n",
    "        description = personalize.describe_dataset_group(datasetGroupArn=dataset_group_arn)\n",
    "        print(description)\n",
    "    else:  # Some other problem\n",
    "        raise err\n",
    "\n",
    "%store dataset_group_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or attach to existing by name:\n",
    "# dataset_group_arn = next(\n",
    "#     group[\"datasetGroupArn\"]\n",
    "#     for group in personalize.list_dataset_groups()[\"datasetGroups\"]\n",
    "#     if group[\"name\"] == # TODO\n",
    "# )\n",
    "# print(dataset_group_arn)\n",
    "# %store dataset_group_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "Let's download the raw data files from S3 and see what we've got.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync --quiet s3://$STAGING_BUCKET/raw ./data/raw\n",
    "!ls -lhR ./data/raw\n",
    "\n",
    "# Ensure empty subfolders in case any datasets were not supplied to CloudFormation:\n",
    "os.makedirs(\"data/raw/interactions\", exist_ok=True)\n",
    "os.makedirs(\"data/raw/items\", exist_ok=True)\n",
    "os.makedirs(\"data/raw/users\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stack is designed to take load data from the public [UCSD Amazon Reviews dataset](https://nijianmo.github.io/amazon/index.html) for `interactions` and `items` data, and takes custom dummy data for `users`.\n",
    "\n",
    "We've supplied some utilities in the `util` folder to transparently handle the UCSD `json.gz` format as well as `csv` - so let's use those pre-built functions to explore the contents of the files, starting with item metadata:\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <p>\n",
    "        <b>Note:</b> Because the items and interactions datasets are potentially very <b>large</b>, we'll\n",
    "        perform streaming analyses where possible, rather than loading straight into memory.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "We'll use a **utility function** `data_folder_reader()`, which is able to loop over records from all the **CSV** and [**JSON-lines**](http://jsonlines.org/) files in the top level of a folder - optionally compressed e.g. as `.csv.gz` or `.json.gz` files.\n",
    "\n",
    "You can explore the implementations of this and other processing functions in [util/dataformat.py](util/dataformat.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items\n",
    "\n",
    "For the **Items** dataset, we'll:\n",
    "\n",
    "* Count the number of items listed\n",
    "* Build a dictionary in memory from item ID to human-readable title (for visualizing recommendations, later)\n",
    "* Print out one item at random (using [Reservoir Sampling](https://en.wikipedia.org/wiki/Reservoir_sampling)) to get an idea of structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import util  # Our local utilities including data_folder_reader\n",
    "\n",
    "item_titles = {}\n",
    "n_items = 0\n",
    "sample_item = None\n",
    "\n",
    "for item in util.dataformat.data_folder_reader(\"data/raw/items\"):\n",
    "    n_items += 1\n",
    "\n",
    "    # Reservoir sampling R-algorithm (simple, non-optimal) with k=1:\n",
    "    if random.randint(1, n_items) <= 1:\n",
    "        sample_item = item\n",
    "\n",
    "    item_titles[util.dataformat.get_item_id(item)] = util.dataformat.get_item_title(item)\n",
    "\n",
    "print(f\"\\nGot {n_items} items total ({len(item_titles)} unique IDs)\")\n",
    "print(\"Sample item:\")\n",
    "print(sample_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a look at some of our item titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for item_id in itertools.islice(item_titles, 5):\n",
    "    print(f\"{item_id} -> {item_titles[item_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions\n",
    "\n",
    "The core dataset we'll train our initial model on is the **interactions** between users and items.\n",
    "\n",
    "For now we'll just count the records and print one at random to explore structure. Some extra checks will follow soon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_interactions = 0\n",
    "sample_interaction = None\n",
    "\n",
    "for interaction in util.dataformat.data_folder_reader(\"data/raw/interactions\"):\n",
    "    n_interactions += 1\n",
    "\n",
    "    # Reservoir sampling R-algorithm (simple, non-optimal) with k=1:\n",
    "    if random.randint(1, n_interactions) <= 1:\n",
    "        sample_interaction = interaction\n",
    "\n",
    "print(f\"\\nGot {n_interactions} interactions total\")\n",
    "print(\"Sample interaction:\")\n",
    "print(sample_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users\n",
    "\n",
    "We don't have any user metadata available for the UCSD Amazon Reviews dataset: The pre-prepared \"users\" datasets just associate a small subset of \"interesting\" user IDs with some dummy metadata.\n",
    "\n",
    "We'll take the same streaming approach to explore the set though, in case you want to work with bigger data. We'll build up a [set](https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset) of the IDs as we go for efficient querying later of whether a user is recognised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 0\n",
    "sample_user = None\n",
    "user_set = set()\n",
    "\n",
    "for user in util.dataformat.data_folder_reader(\"data/raw/users\"):\n",
    "    n_users += 1\n",
    "    user_set.add(util.dataformat.get_user_id(user))\n",
    "\n",
    "    # Reservoir sampling R-algorithm (simple, non-optimal) with k=1:\n",
    "    if random.randint(1, n_users) <= 1:\n",
    "        sample_user = user\n",
    "\n",
    "print(f\"\\nGot {n_users} users total ({len(user_set)} unique IDs)\")\n",
    "print(\"Sample user:\")\n",
    "print(sample_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checks\n",
    "\n",
    "Now that we've loaded our items, interactions and users, we should do some quick checks that our dataset looks feasible to model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "item_interactions = defaultdict(int)  # (dict where unset elements default to 0)\n",
    "user_interactions = defaultdict(int)\n",
    "\n",
    "no_items = 0\n",
    "no_users = 0\n",
    "unknown_items = 0\n",
    "unknown_users = 0\n",
    "\n",
    "print(\"Analysing interactions...\")\n",
    "for event in util.dataformat.data_folder_reader(\"data/raw/interactions\"):\n",
    "    item_id = util.dataformat.get_interaction_item_id(event)\n",
    "    user_id = util.dataformat.get_interaction_user_id(event)\n",
    "\n",
    "    if item_id is None:\n",
    "        no_items += 1\n",
    "    else:\n",
    "        item_interactions[item_id] += 1\n",
    "        if item_id not in item_titles:\n",
    "            unknown_items += 1\n",
    "\n",
    "    if user_id is None:\n",
    "        no_users += 1\n",
    "    else:\n",
    "        user_interactions[user_id] += 1\n",
    "        if user_id not in user_set:\n",
    "            unknown_users += 1\n",
    "\n",
    "print()\n",
    "print(f\"Could not determine item ID for {no_items} interactions\")\n",
    "print(f\"Could not determine user ID for {no_users} interactions\")\n",
    "print(f\"Unrecognised item ID (not in items dataset) for {unknown_items} interactions\")\n",
    "print(f\"Unrecognised user ID (not in users dataset) for {unknown_users} interactions\")\n",
    "print()\n",
    "\n",
    "n_items_interacted = sum(map(lambda iid: item_interactions[iid] > 0, item_titles))\n",
    "print(f\"{n_items_interacted} recognised items interacted with\")\n",
    "n_returning_users = sum(map(lambda uid: user_interactions[uid] > 1, user_set))\n",
    "print(f\"{n_returning_users} recognised users with more 2+ interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Note:</b> we didn't do any hard/error-raising assertions here, but it's important to check your data\n",
    "    meets (and, for good results, easily exceeds) the minimum specifications laid out in the\n",
    "    <a href=\"https://docs.aws.amazon.com/personalize/latest/dg/limits.html\">\n",
    "        Amazon Personalize Service Limits doc</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a schema\n",
    "\n",
    "Now we understand our source data, we need to [import it to Amazon Personalize](https://docs.aws.amazon.com/personalize/latest/dg/data-prep.html).\n",
    "\n",
    "To do this we will:\n",
    "\n",
    "- Format the data as a comma-separated values (CSV) file\n",
    "- Provide a schema so that Amazon Personalize can interpret the data correctly\n",
    "- Upload the CSV to an S3 bucket that Amazon Personalize can access (i.e. our staging bucket)\n",
    "\n",
    "Each **dataset type** (interactions, user metadata, item metadata) has different [required fields and reserved field names](https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html).\n",
    "\n",
    "To keep things simple for our first model, we'll do the bare minimum: Just an interactions dataset including just the required fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "interactions_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        { \"name\": \"USER_ID\", \"type\": \"string\" },\n",
    "        { \"name\": \"ITEM_ID\", \"type\": \"string\" },\n",
    "        { \"name\": \"TIMESTAMP\", \"type\": \"long\" },\n",
    "    ],\n",
    "    \"version\": \"1.0\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    create_schema_response = personalize.create_schema(\n",
    "        name=f\"{os.environ['CF_STACK_NAME']}-schema-interactions\",\n",
    "        schema=json.dumps(interactions_schema)\n",
    "    )\n",
    "\n",
    "    interactions_schema_arn = create_schema_response[\"schemaArn\"]\n",
    "    print(json.dumps(create_schema_response, indent=2))\n",
    "\n",
    "except botoexceptions.ClientError as err:\n",
    "    # If the schema already exists, scrape the ARN from the message and check it:\n",
    "    if err.response[\"Error\"][\"Code\"] == \"ResourceAlreadyExistsException\":\n",
    "        warnings.warn(\n",
    "            \"Schema already exists.\\nScraping ARN from error message.\\n\"\n",
    "            \"To change the existing schema, delete it and re-create it.\"\n",
    "        )\n",
    "        msg = err.response[\"Error\"][\"Message\"]\n",
    "        interactions_schema_arn = msg[msg.index(\"arn:aws:personalize\"):].partition(\" \")[0]\n",
    "        description = personalize.describe_schema(schemaArn=interactions_schema_arn)\n",
    "        print(description)\n",
    "    else:  # Some other problem\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting and uploading the data\n",
    "\n",
    "Next, we convert our data to a CSV (matching the schema) and upload it to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "interactions_filename = \"data/interactions-minimal.csv\"\n",
    "with open(interactions_filename, \"w\") as f:\n",
    "    writer = csv.DictWriter(f, dialect=\"unix\", fieldnames=[\"USER_ID\", \"ITEM_ID\", \"TIMESTAMP\"])\n",
    "    writer.writeheader()\n",
    "    print(\"Writing interactions...\")\n",
    "    for event in util.dataformat.data_folder_reader(\"data/raw/interactions\"):\n",
    "        writer.writerow({\n",
    "            \"USER_ID\": util.dataformat.get_interaction_user_id(event),\n",
    "            \"ITEM_ID\": util.dataformat.get_interaction_item_id(event),\n",
    "            \"TIMESTAMP\": util.dataformat.get_interaction_timestamp(event),\n",
    "        })\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3:\n",
    "s3.Object(os.environ[\"STAGING_BUCKET\"], interactions_filename).upload_file(interactions_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data to Amazon Personalize\n",
    "\n",
    "Now our prep is done, let's put Personalize to work!\n",
    "\n",
    "First, just in case you ran through the last part **super** quickly that our **Dataset Group** is still creating, we'll check and wait for it to become active.\n",
    "\n",
    "Here (and throughout these notebooks) we'll use the handy local `polling_spinner` function from our [util/](util) folder for a nice animated status during the wait:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_group_is_ready(description):\n",
    "    status = description[\"datasetGroup\"][\"status\"]\n",
    "    if status == \"ACTIVE\":\n",
    "        return True\n",
    "    elif \"FAILED\" in status:\n",
    "        raise ValueError(\n",
    "            f\"Wait ended with unexpected status '{status}':\\n{description}\"\n",
    "        )\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(f\"Waiting for dataset group {dataset_group_arn}...\")\n",
    "dataset_group_desc = util.progress.polling_spinner(\n",
    "    # Function to poll (i.e. get the status object):\n",
    "    lambda: personalize.describe_dataset_group(datasetGroupArn=dataset_group_arn),\n",
    "    # Function to determine whether the result is \"finished\":\n",
    "    dataset_group_is_ready,\n",
    "    # Function to represent the result in print():\n",
    "    fn_stringify_result = lambda desc: desc[\"datasetGroup\"][\"status\"],\n",
    "    # Raise an error if we're waiting too long:\n",
    "    timeout_secs=15*60,\n",
    ")\n",
    "dataset_group_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we **create the interactions dataset** container in the Dataset Group, referencing the schema we created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_dataset_response = personalize.create_dataset(\n",
    "        name=f\"{os.environ['CF_STACK_NAME']}-interactions\",\n",
    "        datasetType=\"INTERACTIONS\",\n",
    "        datasetGroupArn=dataset_group_arn,\n",
    "        schemaArn=interactions_schema_arn,\n",
    "    )\n",
    "\n",
    "    interactions_dataset_arn = create_dataset_response[\"datasetArn\"]\n",
    "    print(json.dumps(create_dataset_response, indent=2))\n",
    "\n",
    "except botoexceptions.ClientError as err:\n",
    "    # If the schema already exists, infer the ARN and check it:\n",
    "    if err.response[\"Error\"][\"Code\"] == \"ResourceAlreadyExistsException\":\n",
    "        warnings.warn(\n",
    "            \"Dataset already exists.\\n\"\n",
    "            \"To change the existing dataset's schema, delete it and re-create it.\"\n",
    "        )\n",
    "        interactions_dataset_arn = (\n",
    "            dataset_group_arn.replace(\":dataset-group/\", \":dataset/\")\n",
    "            + \"/INTERACTIONS\"\n",
    "        )\n",
    "        description = personalize.describe_dataset(datasetArn=interactions_dataset_arn)\n",
    "        print(description)\n",
    "    else:  # Some other problem\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a **dataset import job** to validate and import the data to Personalize.\n",
    "\n",
    "This can take a few minutes to complete even with small datasets (due to infrastructure overheads) but scales well to larger imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    # (strftime %f is microseconds, so we trim 3 from the end for milliseconds)\n",
    "    jobName=f\"{os.environ['CF_STACK_NAME']}-interact-{dt.now().strftime('%Y-%m-%d-%H-%M-%S-%f')[:-3]}\",\n",
    "    datasetArn=interactions_dataset_arn,\n",
    "    dataSource={\n",
    "        \"dataLocation\": f\"s3://{os.environ['STAGING_BUCKET']}/{interactions_filename}\"\n",
    "    },\n",
    "    roleArn=role_arn,  # Remember the IAM role we created earlier?\n",
    ")\n",
    "\n",
    "interactions_dataset_import_job_arn = create_dataset_import_job_response[\"datasetImportJobArn\"]\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_import_is_done(description):\n",
    "    status = description[\"datasetImportJob\"][\"status\"]\n",
    "    if status == \"ACTIVE\":\n",
    "        return True\n",
    "    elif \"FAILED\" in status:\n",
    "        raise ValueError(\n",
    "            f\"Wait ended with unexpected status '{status}':\\n{description}\"\n",
    "        )\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(f\"Waiting for dataset import {interactions_dataset_import_job_arn}...\")\n",
    "util.progress.polling_spinner(\n",
    "    lambda: personalize.describe_dataset_import_job(datasetImportJobArn=interactions_dataset_import_job_arn),\n",
    "    dataset_import_is_done,\n",
    "    fn_stringify_result = lambda desc: desc[\"datasetImportJob\"][\"status\"],\n",
    "    timeout_secs=60*60,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model (a \"Solution Version\")\n",
    "\n",
    "Now our data is imported, we can start training models. A trained model in Amazon Personalize is called a **Solution**, or more precisely a **Solution Version** - since models can be re-trained with new data, and a version history will be kept.\n",
    "\n",
    "The **type (or architecture)** of model is determined by the **recipe** we select, so let's start by reviewing what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.list_recipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some of these recipes might be comparable to each other, in many cases it's just a case of choosing the right tool for the right kind of use case:\n",
    "\n",
    "* `Popularity-Count` is just a simple **baseline** model that recommends the most popular items.\n",
    "* `SIMS` recommends items in the **context of both a user and an item** (e.g. 'customers also bought').\n",
    "* `Personalized-Ranking` **re-ranks** a given list of candidate items, to reflect their relevance to the user.\n",
    "* `HRNN`-based models recommend items relevant to a user.\n",
    "\n",
    "For this first model we're just generating personalized homepage recommendations - so we'll choose `HRNN`. We haven't imported any extra metadata, so we'll be using vanilla HRNN rather than the more sophisticated HRNN-based recipes.\n",
    "\n",
    "### Creating the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrnn_arn = \"arn:aws:personalize:::recipe/aws-hrnn\"\n",
    "\n",
    "create_solution_response = personalize.create_solution(\n",
    "    name=f\"{os.environ['CF_STACK_NAME']}-soln-hrnn\",\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    recipeArn=hrnn_arn\n",
    ")\n",
    "\n",
    "hrnn_solution_arn = create_solution_response[\"solutionArn\"]\n",
    "%store hrnn_solution_arn\n",
    "print(json.dumps(create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the solution version (training a model)\n",
    "\n",
    "Because creating the solution version trains the model, this next step will take 20 minutes or more.\n",
    "\n",
    "As before, the second cell polls the status until it completes or fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn=hrnn_solution_arn\n",
    ")\n",
    "\n",
    "hrnn_solution_version_arn = create_solution_version_response[\"solutionVersionArn\"]\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or if you'd like to resume with an existing solution version ARN taken from the console:\n",
    "#hrnn_solution_version_arn = \"arn:aws:personalize:us-east-1:387269085412:solution/thewsfooda-soln-hrnn/68311135\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_version_is_ready(description):\n",
    "    status = description[\"solutionVersion\"][\"status\"]\n",
    "    if status == \"ACTIVE\":\n",
    "        return True\n",
    "    elif \"FAILED\" in status:\n",
    "        raise ValueError(\n",
    "            f\"Wait ended with unexpected status '{status}':\\n{description}\"\n",
    "        )\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(f\"Waiting for solution version {hrnn_solution_version_arn}...\")\n",
    "util.progress.polling_spinner(\n",
    "    lambda: personalize.describe_solution_version(solutionVersionArn=hrnn_solution_version_arn),\n",
    "    solution_version_is_ready,\n",
    "    fn_stringify_result = lambda desc: desc[\"solutionVersion\"][\"status\"],\n",
    "    timeout_secs=3*60*60,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing Solution Metrics\n",
    "\n",
    "As part of the training process, Personalize calculates a range of validation metrics describing the solution's performance on the provided data.\n",
    "\n",
    "These are useful for comparing candidate models offline (e.g. for tuning hyperparameters), or getting an initial idea of how a deployed solution might perform, but **not as concrete** than the kind of metrics we see in other ML applications.\n",
    "\n",
    "This is because of the **interaction** between a deployed recommendation model and users' behavior: The items a user sees influence their decisions, so actual click-through-rate or revenue uplift can be quite different from model metrics.\n",
    "\n",
    "In general these metrics are a good guide to understand candidate models, to be followed by live A/B testing cycles to measure their true impact. For more information on how the metrics are calculated and how to interpret them, see the [\"Evaluating a Solution Version\"](https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html) page in the Personalize Developer Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn=hrnn_solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model (to a \"Campaign\")\n",
    "\n",
    "Amazon Personalize supports both batch and real-time recommendations, but for this website we'll be generating recommendations in real-time so we can respond dynamically to user feedback.\n",
    "\n",
    "We deploy our trained solution version by creating a **campaign**.\n",
    "\n",
    "Note that the campaign is billable for all the time it's deployed (regardless of requests). Here we provision the minimum capacity: There's more information about how capacity and auto-scaling work in the [CreateCampaign API doc](https://docs.aws.amazon.com/personalize/latest/dg/API_CreateCampaign.html).\n",
    "\n",
    "Again, we'll wait for the deployment to become active before testing it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_campaign_response = personalize.create_campaign(\n",
    "    name=f\"{os.environ['CF_STACK_NAME']}-camp-hrnn\",\n",
    "    solutionVersionArn=hrnn_solution_version_arn,\n",
    "    minProvisionedTPS=1,\n",
    ")\n",
    "\n",
    "hrnn_campaign_arn = create_campaign_response[\"campaignArn\"]\n",
    "%store hrnn_campaign_arn\n",
    "print(json.dumps(create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or if you'd like to resume with an existing campaign ARN taken from the console:\n",
    "# hrnn_campaign_arn = \"arn:aws:personalize:us-east-1:387269085412:campaign/thewsfooda-camp-hrnn\"\n",
    "# %store hrnn_campaign_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def campaign_is_ready(description):\n",
    "    status = description[\"campaign\"][\"status\"]\n",
    "    if status == \"ACTIVE\":\n",
    "        return True\n",
    "    elif \"FAILED\" in status:\n",
    "        raise ValueError(\n",
    "            f\"Wait ended with unexpected status '{status}':\\n{description}\"\n",
    "        )\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(f\"Waiting for campaign {hrnn_campaign_arn}...\")\n",
    "util.progress.polling_spinner(\n",
    "    lambda: personalize.describe_campaign(campaignArn=hrnn_campaign_arn),\n",
    "    campaign_is_ready,\n",
    "    fn_stringify_result = lambda desc: desc[\"campaign\"][\"status\"],\n",
    "    timeout_secs=20*60,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting sample recommendations\n",
    "\n",
    "After the campaign is active, we can query it for recommendations.\n",
    "\n",
    "Let's compare what 2 of our users, and an unknown user, would see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, if you wanted to explore users for an interactions dataset where you don't have a list:\n",
    "\n",
    "# candidate_users = []\n",
    "# for uid, nevents in user_interactions.items():\n",
    "#     if nevents >= 10 and nevents < 20:\n",
    "#         candidate_users.append(uid)\n",
    "#     if len(candidate_users) >= 40:\n",
    "#         break\n",
    "\n",
    "# ...and edit the test_users= line below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_users = list(itertools.islice(user_set, 2)) + [\"some-new-person\"]\n",
    "user_recs = []\n",
    "\n",
    "for user_id in test_users:\n",
    "    recs_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn=hrnn_campaign_arn,\n",
    "        userId=str(user_id),\n",
    "    )\n",
    "\n",
    "    # Extract the item IDs from the response:\n",
    "    recommended_ids = [item[\"itemId\"] for item in recs_response[\"itemList\"]]\n",
    "    # Remember we created an `items` dict from item ID to tile earlier?\n",
    "    recommended_titles = [item_titles[item_id] for item_id in recommended_ids]\n",
    "    user_recs.append(pd.Series(recommended_titles, name=user_id))\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 80)  # Increase a bit vs default\n",
    "pd.concat(user_recs, axis=1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <p>\n",
    "        <b>Note:</b> If you see the <i>same recommendations</i> for these users, the IDs in your\n",
    "        <span class=\"code\">users</span> file probably don't feature in your \n",
    "        <span class=\"code\">interactions</span> data.\n",
    "    </p>\n",
    "    <p>\n",
    "        You'll need to check through your interactions data to find some user IDs that do have history, and\n",
    "        then add them to the <b>users table in DynamoDB</b> to make them appear on the website.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enabling recommendations on the website\n",
    "\n",
    "Now we've trained, deployed and briefly validated our model - let's link the website to it!\n",
    "\n",
    "Most of the work has already been done for us by the CloudFormation solution. All we need to do is configure the Lambda function handling homepage recommendations requests: pointing at the newly deployed campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be doing this in a couple of notebooks, so it's packaged in a util function.\n",
    "# The implementation's not very complicated, feel free to go have a look!\n",
    "\n",
    "util.lambdafn.update_lambda_envvar(os.environ[\"LAMBDA_GETRECS_ARN\"], \"CAMPAIGN_ARN\", hrnn_campaign_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "The homepage recommendations on our website are now powered by a basic HRNN model.\n",
    "\n",
    "In the further notebooks, we'll explore:\n",
    "\n",
    "* Using the **Event Tracker** to push real-time feedback in to Personalize to update recommendations\n",
    "* Other ways to embed personalized recommendations in our site, with **\"Similar Items\"** and **Re-ranking** models\n",
    "* Using **metadata** to improve the relevance of our recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To disconnect the campaign we created here from the site, you could either delete the environment variable\n",
    "# through the Lambda function, or uncomment and run the below:\n",
    "\n",
    "# update_lambda_envvar(os.environ[\"LAMBDA_GETRECS_ARN\"], \"CAMPAIGN_ARN\", \"\")\n",
    "# print(\"Disabled per-user recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget that campaigns provision inference capacity: they're billable for all the time they're active!\n",
    "# To dispose of your campaigns after disconnecting them from the website, you can use code something like:\n",
    "# personalize.delete_campaign(campaignArn=hrnn_campaign_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
